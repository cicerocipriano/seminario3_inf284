\documentclass[12pt]{article}

\usepackage{sbc-template}
\usepackage{graphicx,url}
\usepackage[utf8]{inputenc}
\usepackage[brazil]{babel}
\usepackage{listings}


     
\sloppy

\title{Aplicações do problema de Multi-way number partitioning para mercados financeiros de criptomoedas}

\author{Gabriel C. M. Fernandes\inst{1}, Cicero C. Maciel \inst{1}}


\address{ Departamento de Informatica -- Universidade Federal de Viçosa
  (UFV)\\
  Caixa Postal 36570-900 -- Viçosa, MG -- Brasil
  \email{\{gabriel.fernandes1,cicero.maciel\}@ufv.br, @ufv.br}
}

\lstset{frame=tb,
  language=C++}
\setlength{\belowcaptionskip}{10pt}

\begin{document} 

\maketitle


     
\begin{resumo} 

Nesse artigo iremos discutir o uso das metaheurísticas Iterated Greedy e Algoritmo Genético para a resolução do problema da alocação de computadores e mercados em uma empresa financeira e analisaremos sua performance. Esse problema é uma variação mais restrita do Multi-way number partitioning problem com constraints cardinais, sendo inédito na literatura sobre este problema NP-hard.



\end{resumo}


\section{Introdução}


PLACEHOLDER CONTEXTO


\section{Revisão bibliográfica}
Analisando a literatura prévia sobre o MNP, não foram encontrados artigos ou publicações que lidam com a variação discutida neste artigo ou alguma variação similar. Contudo, existem variações de interesse a este trabalho, as chamadas diversity-aware, onde se tem como objetivo diversificar o máximo os conjuntos do Multi-way number partitioning, esse objetivo é o oposto do soft constraint, onde se deseja minimizar a diversidade de mercados em cada computador.  Assim, as técnicas usadas nos MNP  diversity-aware são re-utilizadas neste trabalho como uma referência do que deve ser evitado.

\section{Métodos}

Neste trabalho, todo o código usado foi escrito em C++ e usado na forma de um executável compilado. As metaheurísticas usadas foram a Iterated Greedy (IG) e o Algoritmo Genético (GA), essas duas trabalham em torno de uma classe solução, qual armazena um conjunto de computadores e as informações relacionadas aos valores de cada computador, que são derivados de seus mercados, quais fornecem a média de seus eventos como sua informação principal. 

\subsection{Iterated Greedy}


Na metaheurística Iterated greedy, a busca pela melhor solução começa pela criação de uma solução inicial, por uma função gulosa. A função gulosa ordena os mercados fornecidos pela instância por sua média de eventos em ordem decrescente, e o distribui para os computadores da solução, sendo que o computador com menor soma de seus mercados é o que recebe, isso é feito até os mercados se esgotarem ou até não ser possível achar uma solução que respeite o hard constraint, caso qual faz o programa emitir um erro e parar. Se todos os computadores tiverem sido criados corretamente, a solução inicial recebe eles, tem suas métricas calculadas e é retornada.





\begin{lstlisting}

inline void initial_greedy(instance &inst, solution &sol) {
 

 solution sol =   solution()
  markerts.sort() //Sort em ordem decrescente


  comps = computers()

  for (m in markets)
  {
         auto cm = computador_menor()
         cm.inserir(m)
         
        if(cm.valido == false)
       {
             throw error
       }
  }

  sol.computers = comps;
  sol.calculate_vals()

 return sols

};

\end{lstlisting}
\begingroup
\captionof{lstlisting}{Código da função da solução inicial greedy, em pseudocodígo.}
\endgroup


Após a criação da solução inicial, inicia-se o processo de busca local do Iterated Greedy, nessa etapa são geradas variações da melhor solução, e se alguma delas for melhor que a melhor solução conhecida, ela substitui essa, terminando a busca. Para gerar variações de uma solução são utilizados dois tipos de mudanças, move e swap; No move, um mercado é retirado do computador e adicionado a outro. No swap, os mercados são trocados entre os computadores de maneira cíclica, ou seja,sem mudar o número de mercados em cada computador. 

Após cada mudança, usa-se de uma avaliação parcial para determinar os valores da solução, o uso da avaliação parcial reduz o tempo de execução necessário para processar cada nova solução gerada, possibilitando que a busca local seja mais eficiente do que se necessita-se de uma avaliação completa. Todos os processos acima são repetidos por um número definido de iterações, e depois da conclusão destas, a solução ótima é encontrada.



\begin{lstlisting}

inline void local_search(solution &sol) {

      List<Solutions> sols = List<Solutions>()
      Solution sol = initial_greedy
        
      for i < iterations:
              local_search(sol)
              reconstruct(sol)
              local_search(sol)


     if(validate(sol))
         sols.add(sol)

};

\end{lstlisting}
\begingroup
\captionof{lstlisting}{Código da função da busca local, em pseudocodígo.}
\endgroup




\subsection{Algoritmo Genético}


No Algoritmo genético, a procura pela solução ótima começa pela geração da população inicial do GA, a qual tem um tamanho total definido,e é constituída metade por soluções aleatoriamente geradas e metade por soluções geradas usando a função greedy para criação da solução inicial, todas soluções são armazenadas em um min heap, e são validadas em relação ao hard constraint.


\begin{lstlisting}

inline solution gen_random_sol(instance i) {

      Solution sol = Solution sol()
      
      for (m in i.markets)
      {
               rc=  sol.random_computer()
              rc.markest.add(rc)
      }

      return sol

};

\end{lstlisting}
\begingroup
\captionof{lstlisting}{Código da função de solução inicial aleatoria, em pseudocodígo.}
\endgroup



Após a geração da população inicial, começa-se o processo de reprodução e seleção das soluções. Da população total, são selecionados as soluções com os 25\% melhores valores, essas soluções selecionadas são agrupadas em pares e para cada par são gerados 4 soluções filhas, construídas de uma das metades do conjunto de computadores de cada pai, algumas destas soluções sofrem mutações, mudando aleatoriamente parte de seus computadores. Além disso, as 3\% melhores soluções das soluções escolhidas para se reproduzir são clonadas e inseridas na nova geração, isso é feito para reduzir a probabilidade das novas gerações produzirem resultados piores que as prévias, melhorando assim a performance desta metaheurística. Após cada geração, a melhor solução encontrada é armazenada no min heap,e, após todas as gerações serem criadas, a melhor solução é encontrada no topo deste heap.


\begin{lstlisting}

inline void next_generation(instance i)
{
     list<sols> populacao
    list<sols> good_sols
    list<sols> elite_sols
     for a < i.markets/4
     { 
             good_sols.add( i_markets[a] )
             
             if(a <  i.markets*3/100) 
                     { elite_sols.append( i_markets[a)}
    }

   good_sols.shuffle()

   populacao.clear()

   for a < good_sols.size()
   {

       next = 0
       if(a+1< good_sols.size()) next = a+1
        
       gerar_filhos(a,next)
       if(chance_mut)
       {
                  mutate(filho)
       }
       populacao.add(filhos)


  }

  for e in elite
      populacao.add(e)

    
       
    



};
\end{lstlisting}
\begingroup
\captionof{lstlisting}{Código da função de nova geração, em pseudocodígo.}
\endgroup








\section{Experimentos}

PLACEHOLDER CRIAÇÃO DAS INSTÂNCIAS 

Após a preparação das instâncias, elas são fornecidas ao executável como um argumento da linha de comando, junto ao número de computadores a serem usados no experimento, com esses parâmetros, as metaheurísticas são capazes de procurar a melhor solução, o'que é feito por um número pré-determinado de iterações definido pela metaheurística usada, após a conclusão destas iterações,  a melhor solução encontrado é retornada.



\section{Resultados}


Após a execução das instâncias, obtivemos os seguintes resultados:


\begin{table}[h]
\caption{Valores do desvio padrão}
\label{tab:my-table}
\begin{tabular}{lllll}
       & 2e3c       & 3e4c        & 3e9c            & 4e5c            \\
Random & 9185.24503 & 14777.92231 & 955212763.55824 & 204772960.74668 \\
Guloso & 55.11806   & 79.40521    & 0.4969          & 196373704.18246 \\
IG     & 3.16228    & 1.41421     & 0.4969          & 196373704.18246 \\
GA     & 7.07107    & 31          & 82061251.06896  & 1005662.0189   
\end{tabular}
\end{table}


\begin{table}[h]
\caption{Valores do soft constraint}
\label{tab:my-table}
\begin{tabular}{lllll}
       & 2e3c    & 3e4c    & 3e9c    & 4e5c     \\
Random & 4.10961 & 5.7382  & 2.45271 & 1.3419   \\
Guloso & 8.73053 & 3.03848 & 2.06990 & 12.65008 \\
IG     & 2.35702 & 4.63481 & 7.79603 & 14.10896 \\
GA     & 6.59966 & 5.22074 & 1.98138 & 2.41449 
\end{tabular}
\end{table}

\begin{table}[h]
\caption{Valores do desvio padrão}
\label{tab:my-table}
\begin{tabular}{lllll}
       & 5e9c            & 6e7c            & 7e9c            & 8e9c             \\
Random & 358975385.79006 & 358975385.79006 & 871038693.86482 & 1006239977.42715 \\
Guloso & 0.41574         & 98643338.67584  & 0.4969          & 196373704.18246  \\
IG     & 0.41574         & 98643338.67584  & 0.4969          & 0.4969           \\
GA     & 38719567.45386  & 12386864.89306  & 0.4969          & 54168277.87687  
\end{tabular}
\end{table}


\begin{table}[ht]
\caption{Valores do soft constraint}
\label{tab:my-table}
\begin{tabular}{lllll}
       & 5e9c    & 6e7c    & 7e9c    & 8e9c     \\
Random & 1.49442 & 2.92731 & 1.61148 & 1.24762  \\
Guloso & 1.44476 & 7.25628 & 1.54236 & 12.65008 \\
IG     & 6.70453 & 11.4759 & 5.62647 & 5.78055  \\
GA     & 0.68387 & 1.95114 & 1.17559 & 0.97992 
\end{tabular}
\end{table}

\section{Conclusão}


Assim, com os resultados obtidos, podemos concluir que a performance das metaheurísticas é altamente dependente da instância usada, sendo possível não obter uma melhora significativa sobre a solução inicial gerada pela função greedy. Assim, para se encontrar a melhor distribuição de mercados para o conjunto dado de computadores, devem ser usadas múltiplas metaheurísticas, já que não é possível garantir que o resultado de qualquer meta heurística usada sozinha seja o melhor possível para a situação analisada.



\section{Atribuição}


\end{document}
